## Step 5: Tying it all together
Now that we have all of our helper-cleaner functions, it's time to link them all together. 


### Making a single Cleaner function
`utils.py`

This function will take all of the cleaner functions we defined above and run them together. We do this so we don't have to run each function individually on every tweet. 

</br>

**Step 1:** Define a function called `cleansText` that takes in a **list** of strings called `text_list` and returns a string. Remember to use **type hints**!

Your code should look something like this:
```python
def cleansText(text_list: list) -> str:
```

**Step 2:** Inside the function, create a variable called `whole_text` and set it equal to the string `'summarize: '`. This will be the starting point for our cleaned text.

**Step 3:** Create a for loop that iterates over each string in `text_list`, with `text` as the loop variable. We're looping through `text_list` becuase it contains all of our tweets in a batch, and we want to clean them all at once. 

At this stage, your code should look something like this:
```python

def cleansText(text_list: list) -> str:
  """Given a json in the format of a list, cleans the text of the tweets 
  of urls, emojis, and symbols, preparing it for summerization. Checks for profanity as well. """
  whole_text = 'summarize: '
  for text in text_list:
```
**Step 4:** For each string in the loop, create a variable called `temp_text` and set it equal to the result of calling the `url_free_text` function on the current string. This will remove any URLs from the text.

**Step 5:** Set `temp_text` equal to the result of calling the `give_emoji_free_text` function on temp_text. This will take the URL-free text and remove any emojis from the text.

**Step 6:** Set `temp_text` equal to the result of calling the `symbol_free_text function` on `temp_text`. This will take the URL and Emoji free text and remove any symbols (such as @ or #) from the text.

**Step 7:** Create an `if` statement that checks if the length of `temp_text` is equal to `0`. You can do this with the operator `len(Thing_you_want_the_length_of)`. 

If it is, use the `continue` statement to skip to the next iteration of the loop. This is to ensure that we don't include empty strings in our cleaned text. In other words, if after we clean the string there's nothing left, **don't** add it to the cleaned_text.

At this stage, your code should look something like this:
```python
```python
def cleansText(text_list: list) -> str:
  """Given a json in the format of a list, cleans the text of the tweets 
  of urls, emojis, and symbols, preparing it for summerization. Checks for profanity as well. """
  whole_text = 'summarize: '
  for text in text_list:
    temp_text = url_free_text(text)
    temp_text = give_emoji_free_text(temp_text)
    temp_text = symbol_free_text(temp_text)
    if len(temp_text) == 0:
      continue
```

**Step 8**: Create another `if` statement that checks if the result of calling the `isProfane` function on `temp_text` is True. If it is, use the `continue` statement to skip to the next iteration of the loop. This is to ensure that we don't include any profanity in our cleaned text. 

If you remember, `isProfane()` would return `True` if the given text contained more than 3 instances of profanity. So in other words, if the string is just a string of curse words and nothing meaningful, don't add it to `cleaned_text`.

**Step 9:** Outside of the `if` statements, add `temp_text` to `whole_text` using string concatenation. Here's a hint: use the `+=` operator!

**Step 10:** After the for loop ends, `return` `whole_text`.

Here's what final **cleansText** function should look like:
```python
def cleansText(text_list: list) -> str:
  """Given a json in the format of a list, cleans the text of the tweets 
  of urls, emojis, and symbols, preparing it for summerization. Checks for profanity as well. """
  whole_text = 'summarize: '
  for text in text_list:
    temp_text = url_free_text(text)
    temp_text = give_emoji_free_text(temp_text)
    temp_text = symbol_free_text(temp_text)
    if len(temp_text) == 0:
      continue
    if isProfane(temp_text):
      continue
    whole_text += temp_text
  return whole_text
```
Now that all the filtering is tied together, it's time to move onto the next step!

</br>

### Incorporating the Database
`app.py`

**Step 1:** Define a function called `summaryModel` with a  parameter `type_of_data`. 

This parameter allows you to specify whether you want to create a summary of tweets or articles stored in the database. By setting the value of the parameter in the definition, we set the **defualt value** for this parameter is 'tweets'.

Your code should look like this:
```python
def summaryModel(type_of_data='tweets') -> str:
```

**Step 2:** Inside the function, use an `if` statement to check the value of `type_of_data`. 

If it is equal to 'tweets', create a list called `textList` that contains the 'text' field from each entry in the 'data' field of the db dictionary.

If `type_of_data` is equal to 'articles', make `textList`  contain the 'content' field from each entry in the 'articles' field of the db dictionary.

If type_of_data is neither 'tweets' nor 'articles', make `textList` an empty list.

Your code should now look something like this: 
```python
def summaryModel(type_of_data='tweets') -> str:
  """
  Extracts all tweets from the database, cleans them, creates and returns the summary
  using all tweets from the database.
  """
  if type_of_data == 'tweets':
    textList = [entry['text'] for entry in db['data']]
  elif type_of_data == 'articles':
    textList = [entry['content'] for entry in db['articles']]
  else:
    textList = ['']
```

**Step 3:** Call the `cleansText` function on `textList` and store the result in a variable called `clean_text`. This function will remove any URLs, emojis, and symbols from the text, as well as check for profanity.

**Step 4:** Call the `summarize` function on `clean_text` and store the result in a variable called `summary`. If you remember, this function will use a Huggingface's machine learning model (BART) to create a summary of the text.

Your code should now look something like this: 
```python
def summaryModel(type_of_data='tweets') -> str:
  """
  Extracts all tweets from the database, cleans them, creates and returns the summary
  using all tweets from the database.
  """
  if type_of_data == 'tweets':
    textList = [entry['text'] for entry in db['data']]
  elif type_of_data == 'articles':
    textList = [entry['content'] for entry in db['articles']]
  else:
    textList = ['']

  clean_text = cleansText(textList)
  summary = summarize(input_text=clean_text)[0]['summary_text']
```

**Step 6:** Return the first element of the summary list, which is a dictionary containing the summary text.

Here's what the final function should look like:
```python
def summaryModel(type_of_data='tweets') -> str:
  """
  Extracts all tweets from the database, cleans them, creates and returns the summary
  using all tweets from the database.
  """
  if type_of_data == 'tweets':
    textList = [entry['text'] for entry in db['data']]
  elif type_of_data == 'articles':
    textList = [entry['content'] for entry in db['articles']]
  else:
    textList = ['']

  clean_text = cleansText(textList)
  summary = summarize(input_text=clean_text)[0]['summary_text']

  return summary
```


### Final steps

If it isn't there already, add this line of code along with the others in `app.py`:

```python
  context['articles_summary'] = summaryModel(type_of_data='articles')

```

And with this step, you've finished module 5! 1 more module to go!