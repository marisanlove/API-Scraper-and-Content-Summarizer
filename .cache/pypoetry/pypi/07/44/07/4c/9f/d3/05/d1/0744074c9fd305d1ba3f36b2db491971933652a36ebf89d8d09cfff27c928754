9999999999{"name": "tokenizers", "version": "0.13.2", "summary": "Fast and Customizable Tokenizers", "platform": null, "requires_dist": ["pytest ; extra == 'dev'", "requests ; extra == 'dev'", "numpy ; extra == 'dev'", "datasets ; extra == 'dev'", "black (==22.3) ; extra == 'dev'", "sphinx ; extra == 'docs'", "sphinx-rtd-theme ; extra == 'docs'", "setuptools-rust ; extra == 'docs'", "pytest ; extra == 'testing'", "requests ; extra == 'testing'", "numpy ; extra == 'testing'", "datasets ; extra == 'testing'", "black (==22.3) ; extra == 'testing'"], "requires_python": "", "files": [], "_cache_version": "1.0.0"}